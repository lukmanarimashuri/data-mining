{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Selamat Datang di Halaman Tugas Penambangan Data \u00b6 Nama : Lukman Ari Mashuri NIM : 180411100074 Kelas : Penambangan Data 5D Dosen Pengampu : Mula'ab, S. Si., M. Kom. Jurusan : Teknik Informatika","title":"Home"},{"location":"#selamat-datang-di-halaman-tugas-penambangan-data","text":"Nama : Lukman Ari Mashuri NIM : 180411100074 Kelas : Penambangan Data 5D Dosen Pengampu : Mula'ab, S. Si., M. Kom. Jurusan : Teknik Informatika","title":"Selamat Datang di Halaman Tugas Penambangan Data"},{"location":"Windows/","text":"Windows \u00b6 1. Rata-rata \u00b6 print ( 'jskjsklj' )","title":"**Windows**"},{"location":"Windows/#windows","text":"","title":"Windows"},{"location":"Windows/#1-rata-rata","text":"print ( 'jskjsklj' )","title":"1. Rata-rata"},{"location":"cluster/","text":"CLUSTERING Pengertian Clustering adalah metode pengelompokan data. Clustering bisa disebut sebagai suatu proses untuk mengelompokan data ke dalam beberapa cluster sehingga data dalam satu cluster memiliki tingkat kemiripan yang maksimum dan data antar cluster memiliki kemiripan yang minimum. Clustering merupakan proses partisi satu set objek data ke dalam himpunan bagian yang disebut dengan cluster. Objek yang di dalam cluster memiliki kemiripan karakteristik antar satu sama lainnya dan berbeda dengan cluster yang lain. Partisi tidak dilakukan secara manual melainkan dengan suatu algoritma clustering . Oleh karena itu, clustering sangat berguna dan bisa menemukan group atau kelompokyang tidak dikenal dalam data. Clustering banyak digunakan dalam berbagai aplikasi seperti misalnya pada business inteligence, pengenalan pola citra , web search, bidang ilmu biologi, dan untuk keamanan ( security ). Di dalam business inteligence , clustering bisa mengatur banyak customer ke dalam banyaknya kelompok. Contohnya mengelompokan customer ke dalam beberapa cluster dengan kesamaan karakteristik yang kuat. Clustering juga dikenal sebagai data segmentasi karena clustering mempartisi banyak data set ke dalam banyak group berdasarkan kesamaannya. Selain itu clustering juga bisa sebagai outlier detection . Metode K-Means Clustering K-Means adalah salah satu algoritma clustering / pengelompokan data yang bersifat Unsupervised Learning, yang berarti masukan dari algoritma ini menerima data tanpa label kelas. Secara umum metode k-means ini melakukan proses pengelompokan dengan prosedur sebagai berikut: 1. Menentukan jumlah cluster 2. Mengalokasikan data secara random ke cluster yang ada 3. Menghitung rata-rata setiap cluster dari data yang tergabung sebelumnya 4. Mengalokasikan kembali semua data ke cluster tersebut 5. Mengulang proses nomor 3, sampai tidak ada perubahan atau perubahan yang terjadi masih sudah di bawah treshold Prosedur dasar ini bisa berubah mengikuti pendekatan pengalokasian data yang diterapkan, apakah *crisp* atau *fuzzy*. Setelah meneliti clustering dari sudut yang lain, saya menemukan bahwa *k-means clustering* mempunyai beberapa kelemahan. Fungsi dari algoritma ini adalah mengelompokkan data kedalam beberapa cluster. karakteristik dari algoritma ini adalah : . Memiliki n buah data. . Input berupa jumlah data dan jumlah cluster (kelompok). . Pada setiap cluster/kelompok memiliki sebuah centroid yang mempresentasikan cluster tersebut. Rumus K-Means $$ d(x,y)=|x-y|= \\sqrt{\\sum _ { i = 1 } ^ { n } (x _ { i }-y_{i})^2} $$ Implementasikan K-Means Menggunakan Python from time import time import numpy as np import matplotlib.pyplot as plt from sklearn import metrics from sklearn.cluster import KMeans from sklearn.datasets import load_digits from sklearn.decomposition import PCA from sklearn.preprocessing import scale np . random . seed ( 42 ) digits = load_digits () data = scale ( digits . data ) n_samples , n_features = data . shape n_digits = len ( np . unique ( digits . target )) labels = digits . target sample_size = 300 print ( \"n_digits: %d , \\t n_samples %d , \\t n_features %d \" % ( n_digits , n_samples , n_features )) print ( 82 * '_' ) print ( 'init \\t\\t time \\t inertia \\t homo \\t compl \\t v-meas \\t ARI \\t AMI \\t silhouette' ) def bench_k_means ( estimator , name , data ): t0 = time () estimator . fit ( data ) print ( ' %-9s \\t %.2f s \\t %i \\t %.3f \\t %.3f \\t %.3f \\t %.3f \\t %.3f \\t %.3f ' % ( name , ( time () - t0 ), estimator . inertia_ , metrics . homogeneity_score ( labels , estimator . labels_ ), metrics . completeness_score ( labels , estimator . labels_ ), metrics . v_measure_score ( labels , estimator . labels_ ), metrics . adjusted_rand_score ( labels , estimator . labels_ ), metrics . adjusted_mutual_info_score ( labels , estimator . labels_ , average_method = 'arithmetic' ), metrics . silhouette_score ( data , estimator . labels_ , metric = 'euclidean' , sample_size = sample_size ))) bench_k_means ( KMeans ( init = 'k-means++' , n_clusters = n_digits , n_init = 10 ), name = \"k-means++\" , data = data ) bench_k_means ( KMeans ( init = 'random' , n_clusters = n_digits , n_init = 10 ), name = \"random\" , data = data ) # in this case the seeding of the centers is deterministic, hence we run the # kmeans algorithm only once with n_init=1 pca = PCA ( n_components = n_digits ) . fit ( data ) bench_k_means ( KMeans ( init = pca . components_ , n_clusters = n_digits , n_init = 1 ), name = \"PCA-based\" , data = data ) print ( 82 * '_' ) # Visualize the results on PCA-reduced data reduced_data = PCA ( n_components = 2 ) . fit_transform ( data ) kmeans = KMeans ( init = 'k-means++' , n_clusters = n_digits , n_init = 10 ) kmeans . fit ( reduced_data ) # Step size of the mesh. Decrease to increase the quality of the VQ. h = . 02 # point in the mesh [x_min, x_max]x[y_min, y_max]. # Plot the decision boundary. For that, we will assign a color to each x_min , x_max = reduced_data [:, 0 ] . min () - 1 , reduced_data [:, 0 ] . max () + 1 y_min , y_max = reduced_data [:, 1 ] . min () - 1 , reduced_data [:, 1 ] . max () + 1 xx , yy = np . meshgrid ( np . arange ( x_min , x_max , h ), np . arange ( y_min , y_max , h )) # Obtain labels for each point in mesh. Use last trained model. Z = kmeans . predict ( np . c_ [ xx . ravel (), yy . ravel ()]) # Put the result into a color plot Z = Z . reshape ( xx . shape ) plt . figure ( 1 ) plt . clf () plt . imshow ( Z , interpolation = 'nearest' , extent = ( xx . min (), xx . max (), yy . min (), yy . max ()), cmap = plt . cm . Paired , aspect = 'auto' , origin = 'lower' ) plt . plot ( reduced_data [:, 0 ], reduced_data [:, 1 ], 'k.' , markersize = 2 ) # Plot the centroids as a white X centroids = kmeans . cluster_centers_ plt . scatter ( centroids [:, 0 ], centroids [:, 1 ], marker = 'x' , s = 169 , linewidths = 3 , color = 'w' , zorder = 10 ) plt . title ( 'K-means clustering on the digits dataset (PCA-reduced data) \\n ' 'Centroids are marked with white cross' ) plt . xlim ( x_min , x_max ) plt . ylim ( y_min , y_max ) plt . xticks (()) plt . yticks (()) plt . show () n_digits : 10 , n_samples 1797 , n_features 64 ------ init time inertia homo compl v - meas ARI AMI silhouette k - means ++ 0.19 s 69432 0.602 0.650 0.625 0.465 0.621 0.146 random 0.19 s 69694 0.669 0.710 0.689 0.553 0.686 0.147 PCA - based 0.04 s 70804 0.671 0.698 0.684 0.561 0.681 0.118 ![output_1_1.png](https://github.com/WahyuZ98/Wahyu_Zainur.github.io/blob/master/Clustering%20K-Means/output_1_1.png?raw=true) ### K-Means dengan Tiga Cluster import numpy as np import matplotlib.pyplot as plt # Though the following import is not directly being used, it is required # for 3D projection to work from mpl_toolkits.mplot3d import Axes3D from sklearn.cluster import KMeans from sklearn import datasets np . random . seed ( 5 ) iris = datasets . load_iris () X = iris . data y = iris . target estimators = [( 'k_means_iris_8' , KMeans ( n_clusters = 8 )), ( 'k_means_iris_3' , KMeans ( n_clusters = 3 )), ( 'k_means_iris_bad_init' , KMeans ( n_clusters = 3 , n_init = 1 , init = 'random' ))] fignum = 1 titles = [ '8 clusters' , '3 clusters' , '3 clusters, bad initialization' ] for name , est in estimators : fig = plt . figure ( fignum , figsize = ( 4 , 3 )) ax = Axes3D ( fig , rect = [ 0 , 0 , . 95 , 1 ], elev = 48 , azim = 134 ) est . fit ( X ) labels = est . labels_ ax . scatter ( X [:, 3 ], X [:, 0 ], X [:, 2 ], c = labels . astype ( np . float ), edgecolor = 'k' ) ax . w_xaxis . set_ticklabels ([]) ax . w_yaxis . set_ticklabels ([]) ax . w_zaxis . set_ticklabels ([]) ax . set_xlabel ( 'Petal width' ) ax . set_ylabel ( 'Sepal length' ) ax . set_zlabel ( 'Petal length' ) ax . set_title ( titles [ fignum - 1 ]) ax . dist = 12 fignum = fignum + 1 # Plot the ground truth fig = plt . figure ( fignum , figsize = ( 4 , 3 )) ax = Axes3D ( fig , rect = [ 0 , 0 , . 95 , 1 ], elev = 48 , azim = 134 ) for name , label in [( 'Setosa' , 0 ), ( 'Versicolour' , 1 ), ( 'Virginica' , 2 )]: ax . text3D ( X [ y == label , 3 ] . mean (), X [ y == label , 0 ] . mean (), X [ y == label , 2 ] . mean () + 2 , name , horizontalalignment = 'center' , bbox = dict ( alpha =. 2 , edgecolor = 'w' , facecolor = 'w' )) # Reorder the labels to have colors matching the cluster results y = np . choose ( y , [ 1 , 2 , 0 ]) . astype ( np . float ) ax . scatter ( X [:, 3 ], X [:, 0 ], X [:, 2 ], c = y , edgecolor = 'k' ) ax . w_xaxis . set_ticklabels ([]) ax . w_yaxis . set_ticklabels ([]) ax . w_zaxis . set_ticklabels ([]) ax . set_xlabel ( 'Petal width' ) ax . set_ylabel ( 'Sepal length' ) ax . set_zlabel ( 'Petal length' ) ax . set_title ( 'Ground Truth' ) ax . dist = 12 fig . show () ![output_2_1.png](https://github.com/WahyuZ98/Wahyu_Zainur.github.io/blob/master/Clustering%20K-Means/output_2_1.png?raw=true) ![output_2_2.png](https://github.com/WahyuZ98/Wahyu_Zainur.github.io/blob/master/Clustering%20K-Means/output_2_2.png?raw=true) ![output_2_3.png](https://github.com/WahyuZ98/Wahyu_Zainur.github.io/blob/master/Clustering%20K-Means/output_2_3.png?raw=true) ![output_2_4.png](https://github.com/WahyuZ98/Wahyu_Zainur.github.io/blob/master/Clustering%20K-Means/output_2_4.png?raw=true) ## Metode K-Modes K-Modes merupakan pengembangan dari algoritma clustering K-means untuk menangani data kategorik di mana means diganti oleh modes. K-Modes menggunakan simple matching meassure dalam penentuan similarity dari suatu klaster ###### Implementasi K-Modes Dengan Python menggunakan Random Kategorikal Data import numpy as np from kmodes.kmodes import KModes # random categorical data data = np . random . choice ( 20 , ( 100 , 10 )) km = KModes ( n_clusters = 4 , init = 'Huang' , n_init = 5 , verbose = 1 ) clusters = km . fit_predict ( data ) # Print the cluster centroids print ( km . cluster_centroids_ ) Init : initializing centroids Init : initializing clusters Starting iterations ... Run 1 , iteration : 1 / 100 , moves : 28 , cost : 793.0 Run 1 , iteration : 2 / 100 , moves : 1 , cost : 793.0 Init : initializing centroids Init : initializing clusters Starting iterations ... Run 2 , iteration : 1 / 100 , moves : 28 , cost : 791.0 Run 2 , iteration : 2 / 100 , moves : 4 , cost : 789.0 Run 2 , iteration : 3 / 100 , moves : 3 , cost : 789.0 Init : initializing centroids Init : initializing clusters Starting iterations ... Run 3 , iteration : 1 / 100 , moves : 20 , cost : 797.0 Run 3 , iteration : 2 / 100 , moves : 7 , cost : 792.0 Run 3 , iteration : 3 / 100 , moves : 3 , cost : 792.0 Init : initializing centroids Init : initializing clusters Starting iterations ... Run 4 , iteration : 1 / 100 , moves : 21 , cost : 799.0 Run 4 , iteration : 2 / 100 , moves : 6 , cost : 798.0 Run 4 , iteration : 3 / 100 , moves : 0 , cost : 798.0 Init : initializing centroids Init : initializing clusters Starting iterations ... Run 5 , iteration : 1 / 100 , moves : 18 , cost : 795.0 Run 5 , iteration : 2 / 100 , moves : 6 , cost : 795.0 Best run was number 2 [[ 14 8 0 18 3 7 0 1 16 3 ] [ 7 1 12 4 18 16 5 17 6 2 ] [ 9 17 3 2 11 5 11 0 11 1 ] [ 8 13 8 3 9 0 2 12 6 9 ]] ### Metode K-Prototype Sebelum masuk proses algoritma K-Prototypes tentukan jumlah k yang akan dibentuk batasannya minimal 2 dan maksimal \u221an atau n/2 dimana n adalah jumlah data point atau obyek 1. Tahap 1: \u200b Tentukan K dengan inisial kluster z1, z2, ...,zk secara acak dari n buah titik {x1, x2,...,xn} 2. Tahap 2 \u200b Hitung jarak seluruh data point pada datas et terhadap inisial kluster awal, alokasikan data point ke dalam cluster yang memilik i jarak prototype terdekat dengan object yang diukur. 3. Tahap 3 \u200b Hitung titik pusat cluster yang baru setela h semua objek dialokasikan. Lalu realokasikan semua datapoint pada dataset terhadap prototype yang baru 4. Tahap 4 \u200b jika titik pusat cluster tidak berubah ata u sudah konvergen maka proses algoritma berhenti tetapi jika titik pusat masih be rubah-ubah secara signifikan maka proses kembali ke tahap 2 dan 3 hingga iterasi maksimum tercapai atau sudah tidak ada perpindahan objek. Rumus K-Prototype ![1_HxkHjH647N_9wKjqUBeJiw.png](https://github.com/WahyuZ98/Wahyu_Zainur.github.io/blob/master/Rumus%20K%20Prototype/1_HxkHjH647N_9wKjqUBeJiw.png?raw=true) K- Prototype ini adalah Gabungan data yang ada numerik (data digit) seperti k-Means dan ada data kategorikal dari k-Modes Di bawah ini diberikan adalah kategorisasi set data di atas dengan menggunakan algoritma k-prototype ```python import numpy as np from kmodes.kprototypes import KPrototypes import matplotlib.pyplot as plt from matplotlib import style style.use(\"ggplot\") colors = ['b', 'orange', 'g', 'r', 'c', 'm', 'y', 'k', 'Brown', 'ForestGreen'] #Data points with their publisher name,category score, category name, place name syms = np.genfromtxt('travel.csv', dtype=str, delimiter=',')[:, 1] X = np.genfromtxt('travel.csv', dtype=object, delimiter=',')[:, 2:] X[:, 0] = X[:, 0].astype(float) kproto = KPrototypes(n_clusters=15, init='Cao', verbose=2) clusters = kproto.fit_predict(X, categorical=[1, 2]) # Print cluster centroids of the trained model. print(kproto.cluster_centroids_) # Print training statistics print(kproto.cost_) print(kproto.n_iter_) for s, c in zip(syms, clusters): print(\"Result: {}, cluster:{}\".format(s, c)) # Plot the results for i in set(kproto.labels_): index = kproto.labels_ == i plt.plot(X[index, 0], X[index, 1], 'o') plt.suptitle('Data points categorized with category score', fontsize=18) plt.xlabel('Category Score', fontsize=16) plt.ylabel('Category Type', fontsize=16) plt.show() # Clustered result fig1, ax3 = plt.subplots() scatter = ax3.scatter(syms, clusters, c=clusters, s=50) ax3.set_xlabel('Data points') ax3.set_ylabel('Cluster') plt.colorbar(scatter) ax3.set_title('Data points classifed according to known centers') plt.show() result = zip(syms, kproto.labels_) sortedR = sorted(result, key=lambda x: x[1]) print(sortedR) ``` ```python 240,Ransika Fernando,0.59375,plant,No Data 240,Ransika Fernando,0.04296875,outdoor_,No Data 240,Ransika Fernando,0.26953125,outdoor_road,No Data 241,Sachini Jagodaarachchi,0.98046875,outdoor_mountain,Manigala Mountain 242,Chathuri Senanayake,0.96484375,outdoor_mountain,Adara Kanda 242,Chathuri Senanayake,0.1953125,building_,No Data 242,Chathuri Senanayake,0.00390625,outdoor_,No Data 242,Chathuri Senanayake,0.23046875,building_,Kuwait 242,Chathuri Senanayake,0.2578125,building_street,Kuwait 242,Chathuri Senanayake,0.015625,outdoor_,Kuwait 243,Nilantha Premakumara,0.9453125,sky_sun,No Data 243,Nilantha Premakumara,0.75,outdoor_mountain,No Data 244,Chathuri Senanayake,0.00390625,outdoor_,Trincomalee 244,Chathuri Senanayake,0.6328125,outdoor_oceanbeach,Trincomalee 245,Surangani Bandara,0.7734375,plant_tree,No Data 246,Hasitha Lakmal,0.4140625,people_many,No Data 246,Hasitha Lakmal,0.0078125,outdoor_,No Data 247,Pradeep Kalansooriya,0.40234375,building_,No Data 247,Pradeep Kalansooriya,0.0078125,outdoor_,No Data 248,Dilini Wijesinghe,0.07421875,outdoor_,Victoria Dam 248,Dilini Wijesinghe,0.0078125,others_,Victoria Dam 249,Chiranthi Vinghghani,0.015625,outdoor_,No Data 249,Chiranthi Vinghghani,0.6484375,outdoor_waterside,No Data 250,Janindu Praneeth Weerawarnakula,0.671875,outdoor_oceanbeach,Galle Fort 251,Chathurangi Shyalika,0.00390625,outdoor_,No Data 252,Chathurangi Shyalika,0.9296875,trans_trainstation,No Data 253,Surangani Bandara,0.625,outdoor_field,No Data 253,Surangani Bandara,0.01171875,outdoor_,No Data 254,Surangani Bandara,0.99609375,sky_object,No Data 255,Chathurangi Shyalika,0.00390625,outdoor_,No Data 256,Chathurangi Shyalika,0.33984375,outdoor_field,No Data ```","title":"Clustering"},{"location":"decision_tree/","text":"Decision Tree \u00b6 Decision Tree \u00b6 Decisioin tree adalah alat pendukung keputusan yang menggunakan model keputusan seperti pohon. Decisioin tree (pohon keputusan) biasanya digunakan dalam riset operasi, khususnya dalam analisis keputusan, untuk membantu mengidentifikasi strategi yang paling memungkinkan untuk mencapai tujuan, dan juga merupakan alat yang populer dalam pembelajaran mesin. Dalam ilmu komputer, pembelajaran Decision tree sebagai model prediktif untuk melakukan pengamatan tentang item (diwakili di cabang-cabang) ke kesimpulan tentang nilai target item (diwakili dalam daun). Decision tree ini adalah salah satu pendekatan pemodelan prediktif yang digunakan dalam statistik, penambangan data, dan pembelajaran mesin. Dalam struktur decision tree, daun mewakili label kelas dan cabang mewakili konjungsi fitur yang mengarah ke label kelas tersebut. Decision tree ini di mana variabel target dapat mengambil nilai kontinu yang disebut pohon regresi. Entropy \u00b6 Entropi adalah nilai informasi yang menyatakan ukuran ketidakpastian(impurity) dari attribut dari suatu kumpulan obyek data dalam satuan bit. $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ Keterangan : S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S Gain \u00b6 Gain adalah ukuran efektifitas suatu atribut dalam mengklasifikasikan data, gain digunakan untuk menentukan urutan atribut dimana attribut yang memiliki nilai information Gain terbesar yang dipilih. $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ Keterangan : S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S GINI Index \u00b6 Dalam penerapan GINI index untuk data berskala continuous , terdapat beberapa metode yang dapat digunakan untuk menentukan titik pemecah terbaik, yakni metode brute-force dan metode midpoints . Script \u00b6 # menentukan value atau jenis pada atribut def banyak_elemen ( kolom , data ): kelas = [] for i in range ( len ( data )): if data . values . tolist ()[ i ][ kolom ] not in kelas : kelas . append ( data . values . tolist ()[ i ][ kolom ]) return kelas kelas = banyak_elemen ( df . shape [ 1 ] - 1 , df ) outlook = banyak_elemen ( df . shape [ 1 ] - 5 , df ) temp = banyak_elemen ( df . shape [ 1 ] - 4 , df ) humidity = banyak_elemen ( df . shape [ 1 ] - 3 , df ) windy = banyak_elemen ( df . shape [ 1 ] - 2 , df ) print ( kelas , outlook , temp , humidity , windy ) ` [ 'no' , 'yes' ] [ 'sunny' , 'overcast' , 'rainy' ] [ 'hot' , 'mild' , 'cool' ] [ 'high' , 'normal' ] [ False , True ] # menentukan count value pada Kelas #Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class def countvKelas ( kelas , kolomKelas , data ): hasil = [] for x in range ( len ( kelas )): hasil . append ( 0 ) for i in range ( len ( data )): for j in range ( len ( kelas )): if data . values . tolist ()[ i ][ kolomKelas ] == kelas [ j ]: hasil [ j ] += 1 return hasil pKelas = countvKelas ( kelas , df . shape [ 1 ] - 1 , df ) pKelas [ 5 , 9 ] # menentukan nilai entropy target # Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture def entropy ( T ): hasil = 0 jumlah = 0 for y in T : jumlah += y for z in range ( len ( T )): if jumlah != 0 : T [ z ] = T [ z ] / jumlah for i in T : if i != 0 : hasil -= i * math . log ( i , 2 ) return hasil def e_list ( atribut , n ): temp = [] tx = t_list ( atribut , n ) for i in range ( len ( atribut )): ent = entropy ( tx [ i ]) temp . append ( ent ) return temp tOutlook = t_list ( outlook , 5 ) tTemp = t_list ( temp , 4 ) tHum = t_list ( humidity , 3 ) tWin = t_list ( windy , 2 ) print ( \"Sunny, Overcast, Rainy\" , eOutlook ) print ( \"Hot, Mild, Cold\" , eTemp ) print ( \"High, Normal\" , eHum ) print ( \"False, True\" , eWin ) Sunny , Overcast , Rainy [ 0.9709505944546686 , 0.0 , 0.9709505944546686 ] Hot , Mild , Cold [ 1.0 , 0.9182958340544896 , 0.8112781244591328 ] High , Normal [ 0.9852281360342516 , 0.5916727785823275 ] False , True [ 0.8112781244591328 , 1.0 ] Berikut adalah contoh data yang akan dirubah menjadi decision tree: 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari entropy(s) dari kolom class di atas, diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ Kemudian menghitung gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] \u200b = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) \u200b =1-(10/20 x 0,970951)+(10/20 x 0,970951) \u200b =1-(0,4485475+0,4485475) \u200b =1-0,970951 \u200b =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] \u200b = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) \u200b =1-(0,162256+0+0,217426) \u200b =1-0,379681 \u200b =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] \u200b = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) \u200b =1-(0,242738+0,34483+0,2+0,2) \u200b =1-0,987567 \u200b =0,012433 Referensi \u00b6 https://en.wikipedia.org/wiki/Decision_tree_learning http://dinus.ac.id/repository/docs/ajar/5DecTreeClass.pdf","title":"Decision Tree"},{"location":"decision_tree/#decision-tree","text":"","title":"Decision Tree"},{"location":"decision_tree/#decision-tree_1","text":"Decisioin tree adalah alat pendukung keputusan yang menggunakan model keputusan seperti pohon. Decisioin tree (pohon keputusan) biasanya digunakan dalam riset operasi, khususnya dalam analisis keputusan, untuk membantu mengidentifikasi strategi yang paling memungkinkan untuk mencapai tujuan, dan juga merupakan alat yang populer dalam pembelajaran mesin. Dalam ilmu komputer, pembelajaran Decision tree sebagai model prediktif untuk melakukan pengamatan tentang item (diwakili di cabang-cabang) ke kesimpulan tentang nilai target item (diwakili dalam daun). Decision tree ini adalah salah satu pendekatan pemodelan prediktif yang digunakan dalam statistik, penambangan data, dan pembelajaran mesin. Dalam struktur decision tree, daun mewakili label kelas dan cabang mewakili konjungsi fitur yang mengarah ke label kelas tersebut. Decision tree ini di mana variabel target dapat mengambil nilai kontinu yang disebut pohon regresi.","title":"Decision Tree"},{"location":"decision_tree/#entropy","text":"Entropi adalah nilai informasi yang menyatakan ukuran ketidakpastian(impurity) dari attribut dari suatu kumpulan obyek data dalam satuan bit. $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log_2\\quad pi} $$ Keterangan : S=Himpunan kasus n = jumlah partisi S pi= proposi Si terhadap S","title":"Entropy"},{"location":"decision_tree/#gain","text":"Gain adalah ukuran efektifitas suatu atribut dalam mengklasifikasikan data, gain digunakan untuk menentukan urutan atribut dimana attribut yang memiliki nilai information Gain terbesar yang dipilih. $$ GAIN(S,A)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ Keterangan : S=himpunan kasus n=jumlah partisi S |si|=proporsi terhadap S |s|=jumlah kasus dalam S","title":"Gain"},{"location":"decision_tree/#gini-index","text":"Dalam penerapan GINI index untuk data berskala continuous , terdapat beberapa metode yang dapat digunakan untuk menentukan titik pemecah terbaik, yakni metode brute-force dan metode midpoints .","title":"GINI Index"},{"location":"decision_tree/#script","text":"# menentukan value atau jenis pada atribut def banyak_elemen ( kolom , data ): kelas = [] for i in range ( len ( data )): if data . values . tolist ()[ i ][ kolom ] not in kelas : kelas . append ( data . values . tolist ()[ i ][ kolom ]) return kelas kelas = banyak_elemen ( df . shape [ 1 ] - 1 , df ) outlook = banyak_elemen ( df . shape [ 1 ] - 5 , df ) temp = banyak_elemen ( df . shape [ 1 ] - 4 , df ) humidity = banyak_elemen ( df . shape [ 1 ] - 3 , df ) windy = banyak_elemen ( df . shape [ 1 ] - 2 , df ) print ( kelas , outlook , temp , humidity , windy ) ` [ 'no' , 'yes' ] [ 'sunny' , 'overcast' , 'rainy' ] [ 'hot' , 'mild' , 'cool' ] [ 'high' , 'normal' ] [ False , True ] # menentukan count value pada Kelas #Fungsi countvKelas untuk menghitung berapa perbandingan setiap elemen yang terdapat di class def countvKelas ( kelas , kolomKelas , data ): hasil = [] for x in range ( len ( kelas )): hasil . append ( 0 ) for i in range ( len ( data )): for j in range ( len ( kelas )): if data . values . tolist ()[ i ][ kolomKelas ] == kelas [ j ]: hasil [ j ] += 1 return hasil pKelas = countvKelas ( kelas , df . shape [ 1 ] - 1 , df ) pKelas [ 5 , 9 ] # menentukan nilai entropy target # Fungsi entropy untuk Menghitung nilai entropy pada sebuah fiture/class. fungsi e_list untuk mempermudah penghitungan entropy setiap elemen di dalam sebuah fiture def entropy ( T ): hasil = 0 jumlah = 0 for y in T : jumlah += y for z in range ( len ( T )): if jumlah != 0 : T [ z ] = T [ z ] / jumlah for i in T : if i != 0 : hasil -= i * math . log ( i , 2 ) return hasil def e_list ( atribut , n ): temp = [] tx = t_list ( atribut , n ) for i in range ( len ( atribut )): ent = entropy ( tx [ i ]) temp . append ( ent ) return temp tOutlook = t_list ( outlook , 5 ) tTemp = t_list ( temp , 4 ) tHum = t_list ( humidity , 3 ) tWin = t_list ( windy , 2 ) print ( \"Sunny, Overcast, Rainy\" , eOutlook ) print ( \"Hot, Mild, Cold\" , eTemp ) print ( \"High, Normal\" , eHum ) print ( \"False, True\" , eWin ) Sunny , Overcast , Rainy [ 0.9709505944546686 , 0.0 , 0.9709505944546686 ] Hot , Mild , Cold [ 1.0 , 0.9182958340544896 , 0.8112781244591328 ] High , Normal [ 0.9852281360342516 , 0.5916727785823275 ] False , True [ 0.8112781244591328 , 1.0 ] Berikut adalah contoh data yang akan dirubah menjadi decision tree: 0 1 2 3 4 0 CASTEMER ID GENDER CAR TIPE SHIRT SIZE CLASS 1 1 M FAMILY SMALL C0 2 2 M SPORT MEDIUM C0 3 3 M SPORT MEDIUM C0 4 4 M SPORT LARGE C0 5 5 M SPORT EXTRA LARGE C0 6 6 M SPORT EXTRA LARGE C0 7 7 F SPORT SMALL C0 8 8 F SPORT SMALL C0 9 9 F SPORT MEDIUM C1 10 10 F LUXURY LARGE C1 11 11 M FAMILY LARGE C1 12 12 M FAMILY EXTRA LARGE C1 13 13 M FAMILY MEDIUM C1 14 14 M LUCURY EXTRA LARGE C1 15 15 F LUCURY SMALL C1 16 16 F LUCURY SMALL C1 17 17 F LUCURY MEDIUM C1 18 18 F LUCURY MEDIUM C1 19 19 F LUCURY MEDIUM C1 20 20 F LUCURY LARGE C1 pertama mencari entropy(s) dari kolom class di atas, diket: co=10 = Pi=10/20 c1=10=Pi=10/20 $$ Entropy(S)={\\sum \\limits_{i=1}^{n} -pi\\quad log2\\quad pi} $$ $$ Entropy(S)= -10/20 * log2 10/20 -10/20 *log2 10/20 $$ $$ Entropy(S)= 1 $$ Kemudian menghitung gain setiap kolom di atas: $$ GAIN(GENDER)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(GENDER)= 1-[10/20(6,4)+10/20(4,6)] \u200b = 1-10/20(-6/10 x log2 6/10 - 4/10 x log2 4/10) +10/20(-4/10 x log2 4/10 - 6/10 x log2 6/10 ) \u200b =1-(10/20 x 0,970951)+(10/20 x 0,970951) \u200b =1-(0,4485475+0,4485475) \u200b =1-0,970951 \u200b =0.029049 $$ GAIN(CAR\\quad TIPE)= entropy(S)-{\\sum \\limits_{i=1}^{n} \\frac{|Si|}{|s|}*entropy(Si)} $$ GAIN(CAR TIPE)= 1-[4/20(1,3)+8/20(8,0)+8/20(1,7)] \u200b = 1-4/20(-1/4 x log2 1/4 - 3/4 x log2 3/4) +8/20(-8/8 x log2 8/8 - 0/8 x log2 0/8 )+8/20(-1/8 x log2 1/8 - 7/8 x log2 7/8) \u200b =1-(0,162256+0+0,217426) \u200b =1-0,379681 \u200b =0,620319 GAIN(shirt hat)= 1-[5/20(3,2)+7/20(3,4)+4/20(2,2)+4/20(2,2)] \u200b = 1-5/20(-3/5 x log2 3/5 - 2/5 x log2 2/45 +7/20(-3/7 x log2 3/7 - 4/7 x log2 4/7 )+4/20(-2/4 x log2 2/4 - 2/2 x log2 2/2)+4/20(-2/4 log2 2/4-2/4 log2 2/4) \u200b =1-(0,242738+0,34483+0,2+0,2) \u200b =1-0,987567 \u200b =0,012433","title":"Script"},{"location":"decision_tree/#referensi","text":"https://en.wikipedia.org/wiki/Decision_tree_learning http://dinus.ac.id/repository/docs/ajar/5DecTreeClass.pdf","title":"Referensi"},{"location":"deskriptif/","text":"Statistik Deskriptif \u00b6 Pengertian \u00b6 Statistik deskriptif adalah metode-metode pengumpulan dan penyajian data agar dapat memberikan suatu informasi yang berguna Statistik deskriptif hanya memberikan informasi mengenai data yang telah dimiliki dan menyajikan data dalam bentuk tabel diagram grafik atau dalam bentuk lainnya dalam uraian-uraian yang singkat dan terbatas. Tipe Statistik Deskriptif \u00b6 Mean (Rata-rata) \u00b6 Mean adalah rata-rata dari kumpulan angka, secara khusus, jumlah nilai dibagi dengan banyaknya angka. misal ada sebuah data, maka untuk mencari mean dapat dihitung dengan rumus berikut ini: $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Keterangan: * x bar = x rata-rata * x = data ke n * n = banyaknya data Median \u00b6 Median adalah nilai pemisah bagian tengah dari urutan sebuah data. Median disimbolkan dengan Me . nilali _Quartile__2__ berbeda cara perhitungannya, yakni tergantung banyak data tersebut ganjil atau genap. berikut adalah rumus untuk menghitung median: $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ Keterangan: Me = Median dari kelompok data n = banyak data Modus \u00b6 Modus adalah suatu nilai yang paling sering muncul dalam suatu data. Modus berguna untuk mengetahui tingkat frekuensi terjadinya suatu peristiwa. jika dalam suatu data ada dua nilai dengan frekuensi tertinggi, maka itu disebut bimodal, jika ada tiga disebut trimodal, dan jika ada banyak nilai dengan frekuensi tertinggi maka disebut multimodal. berikut adalah rumus untuk mencari modus dalam sebuah himpunan angka: $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Keterangan: Mo = Modus Tb = tepi bawah b1 = selisih frekuensi antara elemen modus dengan elemet sebelumnya b2 = selisih frekuensi antara elemen modus dengan elemen sesudahnya p = panjang interval nilai b1 dan b2 adalah mutlak (selalu positif) Varians \u00b6 varians adalah ukuran seberapa jauh suatu kumpulan bilangan tersebar, varian merupakan jumlah kuadrat semua deviasi nilai-nilai terhadap rata-rata. berikut adalah rumus untuk mencari nilai varian dari suatu himpunan data: $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ Keterangan: x = rata-rata Xi = rata-rata dari semua titik data n = banyak data Standar Deviasi \u00b6 Standar deviasi adalah nilai yang digunakan untuk menentukan sebaran data dalam sampel, serta seberapa dekat titik data individu ke rata-rata nilai sampel. Standar deviasi dapat dengan mudah dihitung dengan hanya mengakar kuadratkan nilai varians. Jika titik data lebih rendah dari rata-rata maka semakin tinggi standar deviasinya. Untuk menghitung standar deviasi dapat menggunakan rumus berikut: $$ \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$ Skewness \u00b6 Skewness ( kemiringan ) mengacu pada distorsi atau asimetri dalam kurva lonceng simetris, atau distribusi normal dalam suatu set data. Skewness merupakan bentuk ketidaksimetrisan suatu distribusi data. Skewness juga adaalah angka yang menujukkan ketidak miringan atau kemiringan suatu data. berikut adalah rumus untuk mencari skewness: $$ Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ Keterangan: Xi = titik data\\ x = rata-rata n = jumlah titik distribusi o = standar deviasi Quartile \u00b6 Quartile adalah jenis Quantile. Quartile pertama (Q1) didefinisikan sebagai angka tengah antara angka terkecil dan median dari kumpulan data. Kuartil kedua (Q2) adalah median data. Kuartil ketiga (Q3) adalah nilai tengah antara median dan nilai tertinggi dari kumpulan data. Simpelnya, quantile ialah nilai yang dibagi 25%. berikut adalah rumus quantile: $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2= (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ Keterangan: Q = nialai quarter n = banyak data Penerapan Statistik Deskrtiptif dalam Python \u00b6 Alat dan Bahan: \u00b6 buatlah data dengan random di excel terleih dahulu, caranya dengan menggunakan formula =RANDBETWEEN(batas_bawah;batas_atas) . kemudian copast hasil tersebut sebagai values . Setelah itu save as .csv . kita menggunakan library python yakni, pandas dan scipy. Langkah-langkah: \u00b6 Pertama \u00b6 Mengimport library yang telah disiapkan tadi, yakni scipy dan pandas import pandas as pd from scipy import stats Kedua \u00b6 Memuat data .csv yang telah dibuat df = pd . read_csv ( 'data_random.csv' , sep = ';' ) Ketiga \u00b6 Memuat penyimpanan data untuk disimpan kemudian untuk ditampilkan. Kemudian menghitung data yang diambil dari bebrapa kolom dari data file .csv dengan itersi, dan menghitung dengan cara yang telah disediakan di libary pandas. Kemudian visualisasikan data trsebut. data = { \"Stats\" : [ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data , columns = [ 'Stats' ] + [ x for x in df . columns ]) tes stats Tinggi Badan Berat Badan Usia Lingkar Badan Min 140 40 20 70 Max 190 70 50 100 Mean 164.882 54.72 34.832 85.228 Standard Deviasi 15.18 8.96 9.3 8.8 Variasi 230.35 80.27 86.4 77.42 Skewnes -0 0.1 0.08 -0.07 Quantile 1 151 47 27 78 Quantile 2 165 54 34 85 Quantile 3 179 63 43.25 93 Median 165 54 34 85 Modus 142 50 28 93 Referensi \u00b6 https://id.wikipedia.org/wiki/Statistika_deskriptif https://www.investopedia.com/terms/s/skewness.asp https://rumusrumus.com/standar-deviasi/ https://statmat.id/pengertian-statistik-deskriptif-dan-statistik-inferensia/ https://www.asikbelajar.com/pengertian-modus-mode/ https://en.wikipedia.org/wiki/Median https://en.wikipedia.org/wiki/Mean","title":"Statistik Deskriptif"},{"location":"deskriptif/#statistik-deskriptif","text":"","title":"Statistik Deskriptif"},{"location":"deskriptif/#pengertian","text":"Statistik deskriptif adalah metode-metode pengumpulan dan penyajian data agar dapat memberikan suatu informasi yang berguna Statistik deskriptif hanya memberikan informasi mengenai data yang telah dimiliki dan menyajikan data dalam bentuk tabel diagram grafik atau dalam bentuk lainnya dalam uraian-uraian yang singkat dan terbatas.","title":"Pengertian"},{"location":"deskriptif/#tipe-statistik-deskriptif","text":"","title":"Tipe Statistik Deskriptif"},{"location":"deskriptif/#mean-rata-rata","text":"Mean adalah rata-rata dari kumpulan angka, secara khusus, jumlah nilai dibagi dengan banyaknya angka. misal ada sebuah data, maka untuk mencari mean dapat dihitung dengan rumus berikut ini: $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Keterangan: * x bar = x rata-rata * x = data ke n * n = banyaknya data","title":"Mean (Rata-rata)"},{"location":"deskriptif/#median","text":"Median adalah nilai pemisah bagian tengah dari urutan sebuah data. Median disimbolkan dengan Me . nilali _Quartile__2__ berbeda cara perhitungannya, yakni tergantung banyak data tersebut ganjil atau genap. berikut adalah rumus untuk menghitung median: $$ Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil $$ $$ Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap $$ Keterangan: Me = Median dari kelompok data n = banyak data","title":"Median"},{"location":"deskriptif/#modus","text":"Modus adalah suatu nilai yang paling sering muncul dalam suatu data. Modus berguna untuk mengetahui tingkat frekuensi terjadinya suatu peristiwa. jika dalam suatu data ada dua nilai dengan frekuensi tertinggi, maka itu disebut bimodal, jika ada tiga disebut trimodal, dan jika ada banyak nilai dengan frekuensi tertinggi maka disebut multimodal. berikut adalah rumus untuk mencari modus dalam sebuah himpunan angka: $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Keterangan: Mo = Modus Tb = tepi bawah b1 = selisih frekuensi antara elemen modus dengan elemet sebelumnya b2 = selisih frekuensi antara elemen modus dengan elemen sesudahnya p = panjang interval nilai b1 dan b2 adalah mutlak (selalu positif)","title":"Modus"},{"location":"deskriptif/#varians","text":"varians adalah ukuran seberapa jauh suatu kumpulan bilangan tersebar, varian merupakan jumlah kuadrat semua deviasi nilai-nilai terhadap rata-rata. berikut adalah rumus untuk mencari nilai varian dari suatu himpunan data: $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ Keterangan: x = rata-rata Xi = rata-rata dari semua titik data n = banyak data","title":"Varians"},{"location":"deskriptif/#standar-deviasi","text":"Standar deviasi adalah nilai yang digunakan untuk menentukan sebaran data dalam sampel, serta seberapa dekat titik data individu ke rata-rata nilai sampel. Standar deviasi dapat dengan mudah dihitung dengan hanya mengakar kuadratkan nilai varians. Jika titik data lebih rendah dari rata-rata maka semakin tinggi standar deviasinya. Untuk menghitung standar deviasi dapat menggunakan rumus berikut: $$ \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} $$","title":"Standar Deviasi"},{"location":"deskriptif/#skewness","text":"Skewness ( kemiringan ) mengacu pada distorsi atau asimetri dalam kurva lonceng simetris, atau distribusi normal dalam suatu set data. Skewness merupakan bentuk ketidaksimetrisan suatu distribusi data. Skewness juga adaalah angka yang menujukkan ketidak miringan atau kemiringan suatu data. berikut adalah rumus untuk mencari skewness: $$ Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} $$ Keterangan: Xi = titik data\\ x = rata-rata n = jumlah titik distribusi o = standar deviasi","title":"Skewness"},{"location":"deskriptif/#quartile","text":"Quartile adalah jenis Quantile. Quartile pertama (Q1) didefinisikan sebagai angka tengah antara angka terkecil dan median dari kumpulan data. Kuartil kedua (Q2) adalah median data. Kuartil ketiga (Q3) adalah nilai tengah antara median dan nilai tertinggi dari kumpulan data. Simpelnya, quantile ialah nilai yang dibagi 25%. berikut adalah rumus quantile: $$ Q_1 = (n + 1) {1\\over 4} $$ $$ Q_2= (n + 1) {1\\over 2} $$ $$ Q_3 = (n + 1) {3\\over 4} $$ Keterangan: Q = nialai quarter n = banyak data","title":"Quartile"},{"location":"deskriptif/#penerapan-statistik-deskrtiptif-dalam-python","text":"","title":"Penerapan Statistik Deskrtiptif dalam Python"},{"location":"deskriptif/#alat-dan-bahan","text":"buatlah data dengan random di excel terleih dahulu, caranya dengan menggunakan formula =RANDBETWEEN(batas_bawah;batas_atas) . kemudian copast hasil tersebut sebagai values . Setelah itu save as .csv . kita menggunakan library python yakni, pandas dan scipy.","title":"Alat dan Bahan:"},{"location":"deskriptif/#langkah-langkah","text":"","title":"Langkah-langkah:"},{"location":"deskriptif/#pertama","text":"Mengimport library yang telah disiapkan tadi, yakni scipy dan pandas import pandas as pd from scipy import stats","title":"Pertama"},{"location":"deskriptif/#kedua","text":"Memuat data .csv yang telah dibuat df = pd . read_csv ( 'data_random.csv' , sep = ';' )","title":"Kedua"},{"location":"deskriptif/#ketiga","text":"Memuat penyimpanan data untuk disimpan kemudian untuk ditampilkan. Kemudian menghitung data yang diambil dari bebrapa kolom dari data file .csv dengan itersi, dan menghitung dengan cara yang telah disediakan di libary pandas. Kemudian visualisasikan data trsebut. data = { \"Stats\" : [ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] tes = pd . DataFrame ( data , columns = [ 'Stats' ] + [ x for x in df . columns ]) tes stats Tinggi Badan Berat Badan Usia Lingkar Badan Min 140 40 20 70 Max 190 70 50 100 Mean 164.882 54.72 34.832 85.228 Standard Deviasi 15.18 8.96 9.3 8.8 Variasi 230.35 80.27 86.4 77.42 Skewnes -0 0.1 0.08 -0.07 Quantile 1 151 47 27 78 Quantile 2 165 54 34 85 Quantile 3 179 63 43.25 93 Median 165 54 34 85 Modus 142 50 28 93","title":"Ketiga"},{"location":"deskriptif/#referensi","text":"https://id.wikipedia.org/wiki/Statistika_deskriptif https://www.investopedia.com/terms/s/skewness.asp https://rumusrumus.com/standar-deviasi/ https://statmat.id/pengertian-statistik-deskriptif-dan-statistik-inferensia/ https://www.asikbelajar.com/pengertian-modus-mode/ https://en.wikipedia.org/wiki/Median https://en.wikipedia.org/wiki/Mean","title":"Referensi"},{"location":"missingvalue_knn/","text":"Missing Values dengan teknik K-NN \u00b6 Missing Value \u00b6 Missing value (data/nilai yang hilang) adalah suatu informasi yang tidak tersedia dalam suatu data. Missing value biasanya terjadi karena adanya suatu informasi dalam data tidak diberikan, sulit dicari, atau memang informasi tersebut tidak ada. Beberapa metode yang biasa digunakan untuk mencari data yang hilang tersebut, biasanya data diganti nilainya dengan nilai tengah atau dengan menyimpulkan dari nilai yang ada, dan atau munglin bahkan mengabaikan data yang hilang tersebut. Algoritma K-NN (K-Nearest Neighbors) \u00b6 K-NN adalah sebuah metode dimana metode ini melakukan klarifikasi berdasarkan data yang jaraknya paling dekat dengan data yang dicari. Mengatasi Missing Value dengan Metode K-NN pada Bahasa Pemrograman Python \u00b6 Untuk mempermudah dalam proses penyelesaiannya, dapat digunakan yakni library python, yakni pandas dan scipy. # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 80 , np . nan , 65 ], 'Second Score' : [ 80 , 55 , 76 , np . nan ], 'Third Score' :[ np . nan , 60 , 90 , 87 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score 0 100.0 80.0 0.0 1 80.0 55.0 60.0 2 0.0 76.0 90.0 3 65.0 0.0 87.0 Referensi \u00b6 https://www.dictio.id/t/apa-yang-dimaksud-dengan-data-hilang-atau-missing-data-pada-statistik/116500 https://openlibrary.telkomuniversity.ac.id/pustaka/files/114813/jurnal_eproc/imputasi-misssing-data-menggunakan-metode-k-nearest-neighbour-dengan-optimasi-algoritma-memetikamissing-value-imputation-using-k-nearest-neighbour-method-optimized-with-memetic-algorithm.pdf","title":"Missing Value with K Nearest Nei"},{"location":"missingvalue_knn/#missing-values-dengan-teknik-k-nn","text":"","title":"Missing Values dengan teknik K-NN"},{"location":"missingvalue_knn/#missing-value","text":"Missing value (data/nilai yang hilang) adalah suatu informasi yang tidak tersedia dalam suatu data. Missing value biasanya terjadi karena adanya suatu informasi dalam data tidak diberikan, sulit dicari, atau memang informasi tersebut tidak ada. Beberapa metode yang biasa digunakan untuk mencari data yang hilang tersebut, biasanya data diganti nilainya dengan nilai tengah atau dengan menyimpulkan dari nilai yang ada, dan atau munglin bahkan mengabaikan data yang hilang tersebut.","title":"Missing Value"},{"location":"missingvalue_knn/#algoritma-k-nn-k-nearest-neighbors","text":"K-NN adalah sebuah metode dimana metode ini melakukan klarifikasi berdasarkan data yang jaraknya paling dekat dengan data yang dicari.","title":"Algoritma K-NN (K-Nearest Neighbors)"},{"location":"missingvalue_knn/#mengatasi-missing-value-dengan-metode-k-nn-pada-bahasa-pemrograman-python","text":"Untuk mempermudah dalam proses penyelesaiannya, dapat digunakan yakni library python, yakni pandas dan scipy. # importing pandas as pd import pandas as pd # importing numpy as np import numpy as np # dictionary of lists dict = { 'First Score' :[ 100 , 80 , np . nan , 65 ], 'Second Score' : [ 80 , 55 , 76 , np . nan ], 'Third Score' :[ np . nan , 60 , 90 , 87 ]} # creating a dataframe from dictionary df = pd . DataFrame ( dict ) # filling missing value using fillna() df . fillna ( 0 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } First Score Second Score Third Score 0 100.0 80.0 0.0 1 80.0 55.0 60.0 2 0.0 76.0 90.0 3 65.0 0.0 87.0","title":"Mengatasi Missing Value dengan Metode K-NN pada Bahasa Pemrograman Python"},{"location":"missingvalue_knn/#referensi","text":"https://www.dictio.id/t/apa-yang-dimaksud-dengan-data-hilang-atau-missing-data-pada-statistik/116500 https://openlibrary.telkomuniversity.ac.id/pustaka/files/114813/jurnal_eproc/imputasi-misssing-data-menggunakan-metode-k-nearest-neighbour-dengan-optimasi-algoritma-memetikamissing-value-imputation-using-k-nearest-neighbour-method-optimized-with-memetic-algorithm.pdf","title":"Referensi"}]}